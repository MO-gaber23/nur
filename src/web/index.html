<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>NeuroVox Diagnosis</title>
    <style>
        body { font-family: sans-serif; display: flex; flex-direction: column; align-items: center; padding: 50px; background-color: #f0f2f5; }
        .container { background: white; padding: 30px; border-radius: 10px; box-shadow: 0 4px 6px rgba(0,0,0,0.1); text-align: center; }
        button { padding: 10px 20px; font-size: 16px; margin: 10px; cursor: pointer; border: none; border-radius: 5px; }
        #recordBtn { background-color: #e74c3c; color: white; }
        #stopBtn { background-color: #34495e; color: white; }
        #stopBtn:disabled { opacity: 0.5; cursor: not-allowed; }
        #status { margin-top: 20px; font-weight: bold; }
        #result { margin-top: 20px; padding: 15px; border: 1px solid #ddd; display: none; }
        .healthy { color: green; }
        .parkinsons { color: red; }
    </style>
</head>
<body>

<div class="container">
    <h1>NeuroVox Analyzer</h1>
    <p>Press Record, say "Ahhh" for 5 seconds, then press Stop.</p>
    
    <button id="recordBtn">Start Recording</button>
    <button id="stopBtn" disabled>Stop & Analyze</button>

    <div id="status">Ready</div>
    <div id="result"></div>
</div>

<script>
    let mediaRecorder;
    let audioChunks = [];

    const recordBtn = document.getElementById("recordBtn");
    const stopBtn = document.getElementById("stopBtn");
    const status = document.getElementById("status");
    const resultDiv = document.getElementById("result");

    recordBtn.addEventListener("click", async () => {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaRecorder = new MediaRecorder(stream);
        
        mediaRecorder.start();
        audioChunks = [];

        mediaRecorder.ondataavailable = event => {
            audioChunks.push(event.data);
        };

        mediaRecorder.onstop = async () => {
            status.innerText = "Processing...";
            
            // Create a blob from the recording
            // Note: Browsers often record in webm/ogg. If your model needs strict WAV,
            // we may need a backend converter. Most ONNX readers are flexible.
            const audioBlob = new Blob(audioChunks, { type: 'audio/wav' }); 
            const formData = new FormData();
            formData.append("file", audioBlob, "recording.wav");

            // Send to Python Backend
            try {
                const response = await fetch("/analyze", {
                    method: "POST",
                    body: formData
                });
                const data = await response.json();
                
                // Display Result
                resultDiv.style.display = "block";
                status.innerText = "Analysis Complete";
                
                let colorClass = data.diagnosis === "Healthy" ? "healthy" : "parkinsons";
                resultDiv.innerHTML = `
                    <h3>Diagnosis: <span class="${colorClass}">${data.diagnosis}</span></h3>
                    <p>Confidence: ${(data.confidence * 100).toFixed(2)}%</p>
                `;
            } catch (error) {
                status.innerText = "Error analyzing audio";
                console.error(error);
            }
        };

        recordBtn.disabled = true;
        stopBtn.disabled = false;
        status.innerText = "Recording...";
    });

    stopBtn.addEventListener("click", () => {
        mediaRecorder.stop();
        recordBtn.disabled = false;
        stopBtn.disabled = true;
    });
</script>

</body>
</html>
